# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jFAgLTjhYwba8w8JLFxup5GjapWLNkLN
"""

import streamlit as st
import os
import re
import glob
import subprocess

from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableLambda, RunnablePassthrough, RunnableParallel


# -----------------------------
# Streamlit Page Config
# -----------------------------
st.set_page_config(page_title="TubeWise ‚Äì YouTube Summarizer & Q&A", layout="wide")
st.title("üé• TubeWise ‚Äì YouTube Video Summarizer & Q&A")

# -----------------------------
# API Key (Streamlit Secrets)
# -----------------------------
os.environ["GOOGLE_API_KEY"] = st.secrets["GOOGLE_API_KEY"]

# -----------------------------
# Helper Functions
# -----------------------------
def download_subtitles(video_url):
    subprocess.run(
        [
            "yt-dlp",
            "--write-auto-sub",
            "--skip-download",
            "--sub-lang",
            "en.*",
            video_url
        ],
        check=True
    )

def clean_vtt_to_single_doc(vtt_text: str) -> str:
    vtt_text = re.sub(r"WEBVTT.*?\n\n", "", vtt_text, flags=re.DOTALL)
    vtt_text = re.sub(r"Kind:.*\n", "", vtt_text)
    vtt_text = re.sub(r"Language:.*\n", "", vtt_text)
    vtt_text = re.sub(r"\d+:\d+:\d+\.\d+ --> .*", "", vtt_text)
    vtt_text = re.sub(r"\[.*?\]", "", vtt_text)
    vtt_text = re.sub(r"<.*?>", "", vtt_text)

    lines = [line.strip() for line in vtt_text.splitlines() if line.strip()]
    seen = set()
    cleaned = []

    for line in lines:
        key = re.sub(r"\s+", " ", line.lower())
        if key not in seen:
            seen.add(key)
            cleaned.append(line)

    return " ".join(cleaned)


def load_transcript_text():
    vtt_files = glob.glob("*.vtt")
    if not vtt_files:
        return None

    with open(vtt_files[0], "r", encoding="utf-8") as f:
        return clean_vtt_to_single_doc(f.read())


# -----------------------------
# UI: Input
# -----------------------------
video_url = st.text_input("üîó Enter YouTube Video URL")

if st.button("üì• Process Video") and video_url:
    with st.spinner("Downloading and processing transcript..."):
        download_subtitles(video_url)
        single_doc = load_transcript_text()

        if not single_doc:
            st.error("No subtitles found for this video.")
            st.stop()

        splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        chunks = splitter.split_text(single_doc)

        embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2"
        )

        vectorstore = FAISS.from_texts(chunks, embeddings)
        st.session_state["vectorstore"] = vectorstore
        st.success("Video processed successfully ‚úÖ")

# -----------------------------
# Q&A Section
# -----------------------------
if "vectorstore" in st.session_state:
    question = st.text_input("‚ùì Ask a question about the video")

    if st.button("üß† Get Answer") and question:
        retriever = st.session_state["vectorstore"].as_retriever(
            search_type="similarity",
            search_kwargs={"k": 3}
        )

        llm = ChatGoogleGenerativeAI(
            model="gemini-2.5-flash-lite",
            temperature=0
        )

        prompt = PromptTemplate(
            template="""
            Answer the question using ONLY the context below.
            If the answer is not present, say "I don't know".

            Context:
            {context}

            Question:
            {question}
            """,
            input_variables=["context", "question"]
        )

        def format_docs(docs):
            return "\n\n".join(doc.page_content for doc in docs)

        chain = (
            RunnableParallel({
                "context": retriever | RunnableLambda(format_docs),
                "question": RunnablePassthrough()
            })
            | prompt
            | llm
            | StrOutputParser()
        )

        answer = chain.invoke(question)
        st.markdown("### ‚úÖ Answer")
        st.write(answer)