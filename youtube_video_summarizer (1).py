# -*- coding: utf-8 -*-
"""YouTube Video Summarizer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Pf9b4brGhJRgKlzb-eOKaP9larejm423
"""

!pip install -U yt-dlp

!yt-dlp --list-subs https://www.youtube.com/watch?v=aircAruvnKk

!yt-dlp --write-auto-sub --skip-download --sub-lang "en.*" https://www.youtube.com/watch?v=aircAruvnKk

!ls

import re

filename = "But what is a neural network？ ｜ Deep learning chapter 1 [aircAruvnKk].en.vtt"

with open(filename, "r", encoding="utf-8") as f:
    vtt = f.read()

text = re.sub(r"\d+:\d+:\d+\.\d+ --> .*", "", vtt)
text = re.sub(r"<.*?>", "", text)

print(text[:1500])

def clean_vtt_to_single_doc(vtt_text: str) -> str:
    # Remove VTT headers
    vtt_text = re.sub(r"WEBVTT.*?\n\n", "", vtt_text, flags=re.DOTALL)
    vtt_text = re.sub(r"Kind:.*\n", "", vtt_text)
    vtt_text = re.sub(r"Language:.*\n", "", vtt_text)

    # Remove timestamps
    vtt_text = re.sub(r"\d+:\d+:\d+\.\d+ --> .*", "", vtt_text)

    # Remove [Music], [Applause], etc.
    vtt_text = re.sub(r"\[.*?\]", "", vtt_text)

    # Remove HTML tags
    vtt_text = re.sub(r"<.*?>", "", vtt_text)

    # Deduplicate consecutive lines
    lines = vtt_text.splitlines()
    cleaned_lines = []
    prev = ""

    for line in lines:
        line = line.strip()
        if line and line != prev:
            cleaned_lines.append(line)
        prev = line

    # Join into one document
    final_text = " ".join(cleaned_lines)
    final_text = re.sub(r"\s+", " ", final_text).strip()

    return final_text

single_doc = clean_vtt_to_single_doc(text)

print(single_doc[:15000])  # preview

!pip install -U langchain-text-splitters tiktoken

from langchain_text_splitters import RecursiveCharacterTextSplitter

from langchain_text_splitters import RecursiveCharacterTextSplitter

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200,
    separators=["\n\n", "\n", ". ", " ", ""]
)

chunks = text_splitter.split_text(single_doc)

print(len(chunks))
print(chunks[0][:400])

chunks = text_splitter.split_text(single_doc)

print("Total chunks:", len(chunks))
print("\n--- SAMPLE CHUNK ---\n")
print(chunks[0])

!pip install -U faiss-cpu sentence-transformers langchain-community

from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS

embedding_model = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-MiniLM-L6-v2"
)

vectorstore = FAISS.from_texts(
    texts=chunks,
    embedding=embedding_model
)

query = "What is a neural network?"

docs = vectorstore.similarity_search(query, k=3)

for i, doc in enumerate(docs):
    print(f"\n--- Result {i+1} ---")
    print(doc.page_content[:500])

!pip uninstall -y langchain langchain-community langchain-core
!pip install langchain==0.1.20 langchain-community==0.0.38 langchain-core==0.1.52
!pip install langchain-google-genai

import os
os.environ["GOOGLE_API_KEY"] = "AIz02398402388jfnd;feijrlkwesdjfdjfslejioeu6Go4uAcEKqNE7pniAk86eHeCPE"



retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 3})

retriever.invoke('What is deepmind')

from langchain_google_genai import ChatGoogleGenerativeAI

llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash-lite",
    temperature=0
)

from langchain_core.prompts import PromptTemplate

prompt = PromptTemplate(
    template="""
      You are a helpful assistant.
      Answer ONLY from the provided transcript context.
      If the context is insufficient, just say you don't know.

      {context}
      Question: {question}
    """,
    input_variables = ['context', 'question']
)

question          = "How does the video explain the role of neurons and layers in a neural network?"
retrieved_docs    = retriever.invoke(question)

retrieved_docs

from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda
from langchain_core.output_parsers import StrOutputParser

def format_docs(retrieved_docs):
  context_text = "\n\n".join(doc.page_content for doc in retrieved_docs)
  return context_text

parallel_chain = RunnableParallel({
    'context': retriever | RunnableLambda(format_docs),
    'question': RunnablePassthrough()
})

parallel_chain.invoke('What is a neural network')

parser = StrOutputParser()

main_chain = parallel_chain | prompt | llm | parser

main_chain.invoke('Can you summarize the video')

main_chain.invoke('How does the video explain the role of neurons and layers in a neural network?')